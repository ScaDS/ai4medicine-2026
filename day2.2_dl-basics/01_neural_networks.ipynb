{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3036615",
   "metadata": {},
   "source": [
    "# PyTorch MLP on Tabular Medical Data (Breast Cancer)\n",
    "\n",
    "Goal:\n",
    "- Load a tabular breast cancer dataset\n",
    "- Preprocess and split data\n",
    "- Build a neural network in PyTorch\n",
    "- Train with a standard PyTorch training loop\n",
    "- Evaluate performance\n",
    "- Experiment with architecture and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb46abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f62de",
   "metadata": {},
   "source": [
    "### 1) Load breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target  # 0/1 binary labels\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Classes:\", data.target_names.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8794e",
   "metadata": {},
   "source": [
    "### 2) Train/validation/test split\n",
    "We use:\n",
    "- train set: for fitting the model\n",
    "- validation set: for monitoring/tuning\n",
    "- test set: final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0581884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval,\n",
    "    test_size=0.2,\n",
    "    stratify=y_trainval,\n",
    "    random_state=SEED\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:  \", X_val.shape, y_val.shape)\n",
    "print(\"Test: \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac4de0",
   "metadata": {},
   "source": [
    "### 3) Feature scaling (important for neural networks)\n",
    "\n",
    "Fit scaler on training data only, then transform val/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef42e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train_np = y_train.to_numpy().astype(np.float32).reshape(-1, 1)\n",
    "y_val_np = y_val.to_numpy().astype(np.float32).reshape(-1, 1)\n",
    "y_test_np = y_test.to_numpy().astype(np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b348e",
   "metadata": {},
   "source": [
    "### 4) Convert to PyTorch tensors + DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b6e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader))\n",
    "print(\"Val batches:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d014fe",
   "metadata": {},
   "source": [
    "### 5) Define the MLP model\n",
    "\n",
    "Participants can change:\n",
    "- hidden_dims\n",
    "- activation function\n",
    "- dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=(32, 16), activation=\"relu\", dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        act_map = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"tanh\": nn.Tanh,\n",
    "            \"sigmoid\": nn.Sigmoid\n",
    "        }\n",
    "\n",
    "        act_layer = act_map[activation.lower()]\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h))\n",
    "            layers.append(act_layer())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = h\n",
    "\n",
    "        # Binary classification output (logit)\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_tensor.shape[1]\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dims=(32, 16),      # try (16,), (64, 32), (64, 32, 16), ...\n",
    "    activation=\"relu\",         # try \"tanh\"\n",
    "    dropout=0.1                # try 0.0, 0.2, 0.5\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e59b57",
   "metadata": {},
   "source": [
    "### 6) Define loss and optimizer\n",
    "\n",
    "We use:\n",
    "- `BCEWithLogitsLoss` for binary classification\n",
    "- `Adam` optimizer for stable training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34071a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47fb37",
   "metadata": {},
   "source": [
    "### 7) Helper functions for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(xb)                  # shape: (batch, 1)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        all_logits.append(logits.detach().cpu())\n",
    "        all_targets.append(yb.detach().cpu())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    all_logits = torch.cat(all_logits).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    probs = 1 / (1 + np.exp(-all_logits))  # sigmoid for probabilities\n",
    "    preds = (probs >= 0.5).astype(np.float32)\n",
    "\n",
    "    epoch_acc = accuracy_score(all_targets, preds)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_targets.append(yb.cpu())\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "    all_logits = torch.cat(all_logits).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    probs = 1 / (1 + np.exp(-all_logits))\n",
    "    preds = (probs >= 0.5).astype(np.float32)\n",
    "\n",
    "    epoch_acc = accuracy_score(all_targets, preds)\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_auc, probs, preds, all_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74075656",
   "metadata": {},
   "source": [
    "### 8) Training loop (multiple epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ef257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"val_auc\": []\n",
    "}\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_auc, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "    history[\"val_auc\"].append(val_auc)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state_dict = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if epoch == 1 or epoch % 10 == 0 or epoch == num_epochs:\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d}/{num_epochs} | \"\n",
    "            f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f} | \"\n",
    "            f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}, val_auc={val_auc:.4f}\"\n",
    "        )\n",
    "\n",
    "# Restore best validation model\n",
    "if best_state_dict is not None:\n",
    "    model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695189b3",
   "metadata": {},
   "source": [
    "### 9) Plot training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf836d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"Train loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(epochs, history[\"train_acc\"], label=\"Train accuracy\")\n",
    "plt.plot(epochs, history[\"val_acc\"], label=\"Validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a1134",
   "metadata": {},
   "source": [
    "### 10) Final evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_auc, test_probs, test_preds, test_targets = evaluate(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test ROC-AUC: {test_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(test_targets, test_preds, target_names=data.target_names))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
